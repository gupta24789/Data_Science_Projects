{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of mnist_with_keras.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "gfTLvfih8877",
        "colab_type": "text",
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": [
        "# MNIST digits classification with Keras\n",
        "\n",
        "We don't expect you to code anything here because you've already solved it with TensorFlow.\n",
        "\n",
        "But you can appreciate how simpler it is with Keras.\n",
        "\n",
        "We'll be happy if you play around with the architecture though, there're some tips at the end."
      ]
    },
    {
      "metadata": {
        "id": "7CZMk45O8878",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://github.com/hse-aml/intro-to-dl/blob/master/week2/v2/images/mnist_sample.png?raw=1\" style=\"width:30%\">"
      ]
    },
    {
      "metadata": {
        "id": "-zYRdLug9VPq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "eb70d553-e6f1-4092-c3c5-be6f034a778d"
      },
      "cell_type": "code",
      "source": [
        "! wget https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py -O setup_google_colab.py\n",
        "import setup_google_colab\n",
        "setup_google_colab.setup_week2_v2()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Redirecting output to ‘wget-log’.\n",
            "**************************************************\n",
            "inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "**************************************************\n",
            "cifar-10-batches-py.tar.gz\n",
            "**************************************************\n",
            "mnist.npz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7gP59wUB8879",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "4d3f8db0-c63c-4406-af38-68ec9801e8c6"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "import tensorflow as tf\n",
        "print(\"We're using TF\", tf.__version__)\n",
        "import keras\n",
        "print(\"We are using Keras\", keras.__version__)\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"../..\")\n",
        "import keras_utils\n",
        "from keras_utils import reset_tf_session"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We're using TF 1.11.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "We are using Keras 2.0.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "irwjQkc8888A",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Look at the data\n",
        "\n",
        "In this task we have 50000 28x28 images of digits from 0 to 9.\n",
        "We will train a classifier on this data."
      ]
    },
    {
      "metadata": {
        "id": "CAhXlF0P888B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7cb1e141-6f52-4de1-e895-e2a51a596df5"
      },
      "cell_type": "code",
      "source": [
        "import preprocessed_mnist\n",
        "X_train, y_train, X_val, y_val, X_test, y_test = preprocessed_mnist.load_dataset()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "10657792/11490434 [==========================>...] - ETA: 0s"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qci1q61x888E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "outputId": "b789ea1a-c896-405b-b904-89e7a1ce2eab"
      },
      "cell_type": "code",
      "source": [
        "# X contains rgb values divided by 255\n",
        "print(\"X_train [shape %s] sample patch:\\n\" % (str(X_train.shape)), X_train[1, 15:20, 5:10])\n",
        "print(\"A closeup of a sample patch:\")\n",
        "plt.imshow(X_train[1, 15:20, 5:10], cmap=\"Greys\")\n",
        "plt.show()\n",
        "print(\"And the whole sample:\")\n",
        "plt.imshow(X_train[1], cmap=\"Greys\")\n",
        "plt.show()\n",
        "print(\"y_train [shape %s] 10 samples:\\n\" % (str(y_train.shape)), y_train[:10])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train [shape (50000, 28, 28)] sample patch:\n",
            " [[0.         0.29803922 0.96470588 0.98823529 0.43921569]\n",
            " [0.         0.33333333 0.98823529 0.90196078 0.09803922]\n",
            " [0.         0.33333333 0.98823529 0.8745098  0.        ]\n",
            " [0.         0.33333333 0.98823529 0.56862745 0.        ]\n",
            " [0.         0.3372549  0.99215686 0.88235294 0.        ]]\n",
            "A closeup of a sample patch:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPQAAAD4CAYAAADb7cuFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyP8AFG4GWya6GjoAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f1b4704d240>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "And the whole sample:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD4CAYAAADFJPs2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnzPOFW1kYgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f1b47006128>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "y_train [shape (50000,)] 10 samples:\n",
            " [5 0 4 1 9 2 1 3 1 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bZ9vfuCS888H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6d58f379-7105-4445-c150-3b42a6e061a9"
      },
      "cell_type": "code",
      "source": [
        "# flatten images\n",
        "X_train_flat = X_train.reshape((X_train.shape[0], -1))\n",
        "print(X_train_flat.shape)\n",
        "\n",
        "X_val_flat = X_val.reshape((X_val.shape[0], -1))\n",
        "print(X_val_flat.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 784)\n",
            "(10000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eeOuhuw7888K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "2406de60-a51b-44c7-fef9-a78593e80027"
      },
      "cell_type": "code",
      "source": [
        "# one-hot encode the target\n",
        "y_train_oh = keras.utils.to_categorical(y_train, 10)\n",
        "y_val_oh = keras.utils.to_categorical(y_val, 10)\n",
        "\n",
        "print(y_train_oh.shape)\n",
        "print(y_train_oh[:3], y_train[:3])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 10)\n",
            "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]] [5 0 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "z61HK960888O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# building a model with keras\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.models import Sequential\n",
        "\n",
        "# we still need to clear a graph though\n",
        "s = reset_tf_session()\n",
        "\n",
        "model = Sequential()  # it is a feed-forward network without loops like in RNN\n",
        "model.add(Dense(256, input_shape=(784,)))  # the first layer must specify the input shape (replacing placeholders)\n",
        "model.add(Activation('sigmoid'))\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('sigmoid'))\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V3Tz_Rug888R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "d17aa712-2222-46dd-caae-a3ab62c3be5e"
      },
      "cell_type": "code",
      "source": [
        "# you can look at all layers and parameter count\n",
        "model.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 256)               200960    \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                2570      \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 269,322\n",
            "Trainable params: 269,322\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dAUnAbZU888U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "b3cf74ab-dc81-44d6-d696-d23f812af6fa"
      },
      "cell_type": "code",
      "source": [
        "# now we \"compile\" the model specifying the loss and optimizer\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy', # this is our cross-entropy\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']  # report accuracy during training\n",
        ")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2745: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1299: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Jf16gHW2888X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2754
        },
        "outputId": "44ae36e1-f74a-48e1-9624-171098e3e7be"
      },
      "cell_type": "code",
      "source": [
        "# and now we can fit the model with model.fit()\n",
        "# and we don't have to write loops and batching manually as in TensorFlow\n",
        "model.fit(\n",
        "    X_train_flat, \n",
        "    y_train_oh,\n",
        "    batch_size=512, \n",
        "    epochs=40,\n",
        "    validation_data=(X_val_flat, y_val_oh),\n",
        "    callbacks=[keras_utils.TqdmProgressCallback()],\n",
        "    verbose=0\n",
        ")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1/40\n",
            "**************************************************\n",
            "loss: 1.1887; acc: 0.7093; val_loss: 0.4460; val_acc: 0.8932\n",
            "\n",
            "Epoch 2/40\n",
            "**************************************************\n",
            "loss: 0.3782; acc: 0.8968; val_loss: 0.2898; val_acc: 0.9198\n",
            "\n",
            "Epoch 3/40\n",
            "**************************************************\n",
            "loss: 0.2872; acc: 0.9172; val_loss: 0.2414; val_acc: 0.9311\n",
            "\n",
            "Epoch 4/40\n",
            "**************************************************\n",
            "loss: 0.2446; acc: 0.9286; val_loss: 0.2155; val_acc: 0.9376\n",
            "\n",
            "Epoch 5/40\n",
            "**************************************************\n",
            "loss: 0.2149; acc: 0.9369; val_loss: 0.1930; val_acc: 0.9447\n",
            "\n",
            "Epoch 6/40\n",
            "**************************************************\n",
            "loss: 0.1903; acc: 0.9441; val_loss: 0.1729; val_acc: 0.9537\n",
            "\n",
            "Epoch 7/40\n",
            "**************************************************\n",
            "loss: 0.1704; acc: 0.9493; val_loss: 0.1591; val_acc: 0.9563\n",
            "\n",
            "Epoch 8/40\n",
            "**************************************************\n",
            "loss: 0.1539; acc: 0.9552; val_loss: 0.1476; val_acc: 0.9586\n",
            "\n",
            "Epoch 9/40\n",
            "**************************************************\n",
            "loss: 0.1383; acc: 0.9597; val_loss: 0.1362; val_acc: 0.9615\n",
            "\n",
            "Epoch 10/40\n",
            "**************************************************\n",
            "loss: 0.1263; acc: 0.9632; val_loss: 0.1307; val_acc: 0.9622\n",
            "\n",
            "Epoch 11/40\n",
            "**************************************************\n",
            "loss: 0.1129; acc: 0.9672; val_loss: 0.1220; val_acc: 0.9656\n",
            "\n",
            "Epoch 12/40\n",
            "**************************************************\n",
            "loss: 0.1035; acc: 0.9702; val_loss: 0.1174; val_acc: 0.9654\n",
            "\n",
            "Epoch 13/40\n",
            "**************************************************\n",
            "loss: 0.0941; acc: 0.9728; val_loss: 0.1093; val_acc: 0.9683\n",
            "\n",
            "Epoch 14/40\n",
            "**************************************************\n",
            "loss: 0.0853; acc: 0.9762; val_loss: 0.1045; val_acc: 0.9707\n",
            "\n",
            "Epoch 15/40\n",
            "**************************************************\n",
            "loss: 0.0780; acc: 0.9774; val_loss: 0.0986; val_acc: 0.9706\n",
            "\n",
            "Epoch 16/40\n",
            "**************************************************\n",
            "loss: 0.0702; acc: 0.9800; val_loss: 0.0958; val_acc: 0.9713\n",
            "\n",
            "Epoch 17/40\n",
            "**************************************************\n",
            "loss: 0.0649; acc: 0.9821; val_loss: 0.0933; val_acc: 0.9729\n",
            "\n",
            "Epoch 18/40\n",
            "**************************************************\n",
            "loss: 0.0588; acc: 0.9833; val_loss: 0.0919; val_acc: 0.9720\n",
            "\n",
            "Epoch 19/40\n",
            "**************************************************\n",
            "loss: 0.0527; acc: 0.9853; val_loss: 0.0851; val_acc: 0.9746\n",
            "\n",
            "Epoch 20/40\n",
            "**************************************************\n",
            "loss: 0.0476; acc: 0.9870; val_loss: 0.0869; val_acc: 0.9752\n",
            "\n",
            "Epoch 21/40\n",
            "**************************************************\n",
            "loss: 0.0436; acc: 0.9883; val_loss: 0.0820; val_acc: 0.9757\n",
            "\n",
            "Epoch 22/40\n",
            "**************************************************\n",
            "loss: 0.0392; acc: 0.9899; val_loss: 0.0801; val_acc: 0.9763\n",
            "\n",
            "Epoch 23/40\n",
            "**************************************************\n",
            "loss: 0.0355; acc: 0.9910; val_loss: 0.0795; val_acc: 0.9767\n",
            "\n",
            "Epoch 24/40\n",
            "**************************************************\n",
            "loss: 0.0316; acc: 0.9927; val_loss: 0.0822; val_acc: 0.9757\n",
            "\n",
            "Epoch 25/40\n",
            "**************************************************\n",
            "loss: 0.0291; acc: 0.9933; val_loss: 0.0783; val_acc: 0.9771\n",
            "\n",
            "Epoch 26/40\n",
            "**************************************************\n",
            "loss: 0.0256; acc: 0.9942; val_loss: 0.0778; val_acc: 0.9774\n",
            "\n",
            "Epoch 27/40\n",
            "**************************************************\n",
            "loss: 0.0237; acc: 0.9948; val_loss: 0.0749; val_acc: 0.9779\n",
            "\n",
            "Epoch 28/40\n",
            "**************************************************\n",
            "loss: 0.0210; acc: 0.9956; val_loss: 0.0755; val_acc: 0.9787\n",
            "\n",
            "Epoch 29/40\n",
            "**************************************************\n",
            "loss: 0.0191; acc: 0.9961; val_loss: 0.0770; val_acc: 0.9773\n",
            "\n",
            "Epoch 30/40\n",
            "**************************************************\n",
            "loss: 0.0168; acc: 0.9969; val_loss: 0.0746; val_acc: 0.9772\n",
            "\n",
            "Epoch 31/40\n",
            "**************************************************\n",
            "loss: 0.0155; acc: 0.9974; val_loss: 0.0781; val_acc: 0.9781\n",
            "\n",
            "Epoch 32/40\n",
            "**************************************************\n",
            "loss: 0.0141; acc: 0.9979; val_loss: 0.0758; val_acc: 0.9789\n",
            "\n",
            "Epoch 33/40\n",
            "**************************************************\n",
            "loss: 0.0125; acc: 0.9981; val_loss: 0.0777; val_acc: 0.9783\n",
            "\n",
            "Epoch 34/40\n",
            "**************************************************\n",
            "loss: 0.0111; acc: 0.9986; val_loss: 0.0762; val_acc: 0.9790\n",
            "\n",
            "Epoch 35/40\n",
            "**************************************************\n",
            "loss: 0.0100; acc: 0.9988; val_loss: 0.0761; val_acc: 0.9792\n",
            "\n",
            "Epoch 36/40\n",
            "**************************************************\n",
            "loss: 0.0087; acc: 0.9990; val_loss: 0.0752; val_acc: 0.9788\n",
            "\n",
            "Epoch 37/40\n",
            "**************************************************\n",
            "loss: 0.0078; acc: 0.9993; val_loss: 0.0784; val_acc: 0.9786\n",
            "\n",
            "Epoch 38/40\n",
            "**************************************************\n",
            "loss: 0.0071; acc: 0.9994; val_loss: 0.0769; val_acc: 0.9795\n",
            "\n",
            "Epoch 39/40\n",
            "**************************************************\n",
            "loss: 0.0063; acc: 0.9995; val_loss: 0.0752; val_acc: 0.9797\n",
            "\n",
            "Epoch 40/40\n",
            "**************************************************\n",
            "loss: 0.0057; acc: 0.9996; val_loss: 0.0765; val_acc: 0.9797\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1b424e4d30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "Qlm6ECuQ888d",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Here're the notes for those who want to play around here\n",
        "\n",
        "Here are some tips on what you could do:\n",
        "\n",
        " * __Network size__\n",
        "   * More neurons, \n",
        "   * More layers, ([docs](https://keras.io/))\n",
        "\n",
        "   * Other nonlinearities in the hidden layers\n",
        "     * tanh, relu, leaky relu, etc\n",
        "   * Larger networks may take more epochs to train, so don't discard your net just because it could didn't beat the baseline in 5 epochs.\n",
        "\n",
        "\n",
        " * __Early Stopping__\n",
        "   * Training for 100 epochs regardless of anything is probably a bad idea.\n",
        "   * Some networks converge over 5 epochs, others - over 500.\n",
        "   * Way to go: stop when validation score is 10 iterations past maximum\n",
        "     \n",
        "\n",
        " * __Faster optimization__\n",
        "   * rmsprop, nesterov_momentum, adam, adagrad and so on.\n",
        "     * Converge faster and sometimes reach better optima\n",
        "     * It might make sense to tweak learning rate/momentum, other learning parameters, batch size and number of epochs\n",
        "\n",
        "\n",
        " * __Regularize__ to prevent overfitting\n",
        "   * Add some L2 weight norm to the loss function, theano will do the rest\n",
        "     * Can be done manually or via - https://keras.io/regularizers/\n",
        "   \n",
        "   \n",
        " * __Data augmemntation__ - getting 5x as large dataset for free is a great deal\n",
        "   * https://keras.io/preprocessing/image/\n",
        "   * Zoom-in+slice = move\n",
        "   * Rotate+zoom(to remove black stripes)\n",
        "   * any other perturbations\n",
        "   * Simple way to do that (if you have PIL/Image): \n",
        "     * ```from scipy.misc import imrotate,imresize```\n",
        "     * and a few slicing\n",
        "   * Stay realistic. There's usually no point in flipping dogs upside down as that is not the way you usually see them."
      ]
    },
    {
      "metadata": {
        "id": "GSSNX1Nl888e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}