{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of RNN-task.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "aq6GruCPUHRu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Generating names with recurrent neural networks\n",
        "\n",
        "This time you'll find yourself delving into the heart (and other intestines) of recurrent neural networks on a class of toy problems.\n",
        "\n",
        "Struggle to find a name for the variable? Let's see how you'll come up with a name for your son/daughter. Surely no human has expertize over what is a good child name, so let us train RNN instead;\n",
        "\n",
        "It's dangerous to go alone, take these:"
      ]
    },
    {
      "metadata": {
        "id": "2ymdxFK0UN3h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "913b2f6b-77f5-422e-ece4-3f22735e6d59"
      },
      "cell_type": "code",
      "source": [
        "! shred -u setup_google_colab.py\n",
        "! wget https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py -O setup_google_colab.py\n",
        "import setup_google_colab\n",
        "# please, uncomment the week you're working on\n",
        "# setup_google_colab.setup_week1()\n",
        "# setup_google_colab.setup_week2()\n",
        "# setup_google_colab.setup_week3()\n",
        "# setup_google_colab.setup_week4()\n",
        "setup_google_colab.setup_week5()\n",
        "# setup_google_colab.setup_week6()\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shred: setup_google_colab.py: failed to open for writing: No such file or directory\n",
            "--2018-10-23 17:05:44--  https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3595 (3.5K) [text/plain]\n",
            "Saving to: ‘setup_google_colab.py’\n",
            "\n",
            "setup_google_colab. 100%[===================>]   3.51K  --.-KB/s    in 0s      \n",
            "\n",
            "2018-10-23 17:05:44 (53.2 MB/s) - ‘setup_google_colab.py’ saved [3595/3595]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.696201Z",
          "start_time": "2018-08-13T20:26:38.104103Z"
        },
        "id": "gi5PGKBFUHRx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b81bfb93-3bc8-4029-e0a8-000f5792039e"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import os\n",
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "import keras_utils\n",
        "import tqdm_utils"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.12.0-rc1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5eluQp_ZUHR1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load data\n",
        "The dataset contains ~8k earthling names from different cultures, all in latin transcript.\n",
        "\n",
        "This notebook has been designed so as to allow you to quickly swap names for something similar: deep learning article titles, IKEA furniture, pokemon names, etc."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.701832Z",
          "start_time": "2018-08-13T20:26:42.697766Z"
        },
        "id": "ePcSm3L9UHR2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "start_token = \" \"  # so that the network knows that we're generating a first token\n",
        "\n",
        "# this is the token for padding,\n",
        "# we will add fake pad token at the end of names \n",
        "# to make them of equal size for further batching\n",
        "pad_token = \"#\"\n",
        "\n",
        "with open(\"names\") as f:\n",
        "    names = f.read()[:-1].split('\\n')\n",
        "    names = [start_token + name for name in names]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.707885Z",
          "start_time": "2018-08-13T20:26:42.703302Z"
        },
        "id": "t4iXlXz3UHR5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "7a9e71f3-b58c-4cb8-f3ff-cac1620e62f5"
      },
      "cell_type": "code",
      "source": [
        "print('number of samples:', len(names))\n",
        "for x in names[::1000]:\n",
        "    print(x)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of samples: 7944\n",
            " Abagael\n",
            " Claresta\n",
            " Glory\n",
            " Liliane\n",
            " Prissie\n",
            " Geeta\n",
            " Giovanne\n",
            " Piggy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.857411Z",
          "start_time": "2018-08-13T20:26:42.709371Z"
        },
        "id": "i5ji6AmOUHR8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "1e4ad78d-cd6e-414e-9f29-d6129ccb5c41"
      },
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = max(map(len, names))\n",
        "print(\"max length:\", MAX_LENGTH)\n",
        "\n",
        "plt.title('Sequence length distribution')\n",
        "plt.hist(list(map(len, names)), bins=25);"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max length: 16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEHCAYAAACgHI2PAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fbde8757f98>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "K_4TWGPlUHR_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Text processing\n",
        "\n",
        "First we need to collect a \"vocabulary\" of all unique tokens i.e. unique characters. We can then encode inputs as a sequence of character ids."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.864592Z",
          "start_time": "2018-08-13T20:26:42.858725Z"
        },
        "id": "gHmRXV9BUHSA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "54212b4c-05df-4a7f-bf57-b627b28069f3"
      },
      "cell_type": "code",
      "source": [
        "tokens = set(''.join(names[:]) + '#')  ### YOUR CODE HERE: all unique characters go here, padding included!\n",
        "\n",
        "tokens = list(tokens)\n",
        "n_tokens = len(tokens)\n",
        "print ('n_tokens:', n_tokens)\n",
        "\n",
        "assert 50 < n_tokens < 60"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "n_tokens: 56\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "V56Yv31EUHSH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Cast everything from symbols into identifiers\n",
        "\n",
        "Tensorflow string manipulation is a bit tricky, so we'll work around it. \n",
        "We'll feed our recurrent neural network with ids of characters from our dictionary.\n",
        "\n",
        "To create such dictionary, let's assign `token_to_id`"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.870330Z",
          "start_time": "2018-08-13T20:26:42.866135Z"
        },
        "id": "SRh8K33PUHSI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "token_to_id = {token:index for index,token in enumerate(tokens)}### YOUR CODE HERE: create a dictionary of {symbol -> its  index in tokens}\n",
        "\n",
        "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.875943Z",
          "start_time": "2018-08-13T20:26:42.871834Z"
        },
        "id": "vatQJZCjUHSM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def to_matrix(names, max_len=None, pad=token_to_id[pad_token], dtype=np.int32):\n",
        "    \"\"\"Casts a list of names into rnn-digestable padded matrix\"\"\"\n",
        "    \n",
        "    max_len = max_len or max(map(len, names))\n",
        "    names_ix = np.zeros([len(names), max_len], dtype) + pad\n",
        "\n",
        "    for i in range(len(names)):\n",
        "        name_ix = list(map(token_to_id.get, names[i]))\n",
        "        names_ix[i, :len(name_ix)] = name_ix\n",
        "\n",
        "    return names_ix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.883107Z",
          "start_time": "2018-08-13T20:26:42.877186Z"
        },
        "id": "6tjPq6pkUHSO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "f738fcbf-1a35-40ea-d17d-da3e3c4e1661"
      },
      "cell_type": "code",
      "source": [
        "# Example: cast 4 random names to padded matrices (so that we can easily batch them)\n",
        "print('\\n'.join(names[::2000]))\n",
        "print(to_matrix(names[::2000]))"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Abagael\n",
            " Glory\n",
            " Prissie\n",
            " Giovanne\n",
            "[[46 11 42 40  9 40 28 13 43]\n",
            " [46 49 13 51  6 39 43 43 43]\n",
            " [46  7  6 22 17 17 22 28 43]\n",
            " [46 49 22 51 30 40 23 23 28]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0_6uCvM0UHSS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Defining a recurrent neural network\n",
        "\n",
        "We can rewrite recurrent neural network as a consecutive application of dense layer to input $x_t$ and previous rnn state $h_t$. This is exactly what we're gonna do now.\n",
        "<img src=\"https://github.com/hse-aml/intro-to-dl/blob/master/week5/rnn.png?raw=1\" width=600>\n",
        "\n",
        "Since we're training a language model, there should also be:\n",
        "* An embedding layer that converts character id x_t to a vector.\n",
        "* An output layer that predicts probabilities of next phoneme based on h_t+1"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.039419Z",
          "start_time": "2018-08-13T20:26:42.884581Z"
        },
        "id": "ufatLQptUHSU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# remember to reset your session if you change your graph!\n",
        "s = keras_utils.reset_tf_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.044903Z",
          "start_time": "2018-08-13T20:26:44.041084Z"
        },
        "id": "mzPewBnlUHSW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.layers import concatenate, Dense, Embedding\n",
        "\n",
        "rnn_num_units = 64  # size of hidden state\n",
        "embedding_size = 16  # for characters\n",
        "\n",
        "# Let's create layers for our recurrent network\n",
        "# Note: we create layers but we don't \"apply\" them yet (this is a \"functional API\" of Keras)\n",
        "# Note: set the correct activation (from keras.activations) to Dense layers!\n",
        "\n",
        "# an embedding layer that converts character ids into embeddings\n",
        "embed_x = Embedding(n_tokens, embedding_size)\n",
        "\n",
        "# a dense layer that maps input and previous state to new hidden state, [x_t,h_t]->h_t+1\n",
        "get_h_next = Dense(rnn_num_units, activation=\"relu\") ### YOUR CODE HERE\n",
        "\n",
        "# a dense layer that maps current hidden state to probabilities of characters [h_t+1]->P(x_t+1|h_t+1)\n",
        "get_probas =  Dense(n_tokens, activation=\"softmax\") ### YOUR CODE HERE "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Rd4budWXUHSZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We will generate names character by character starting with `start_token`:\n",
        "\n",
        "<img src=\"https://github.com/hse-aml/intro-to-dl/blob/master/week5/char-nn.png?raw=1\" width=600>"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.053212Z",
          "start_time": "2018-08-13T20:26:44.048389Z"
        },
        "id": "-b1k3DsIUHSa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def rnn_one_step(x_t, h_t):\n",
        "    \"\"\"\n",
        "    Recurrent neural network step that produces \n",
        "    probabilities for next token x_t+1 and next state h_t+1\n",
        "    given current input x_t and previous state h_t.\n",
        "    We'll call this method repeatedly to produce the whole sequence.\n",
        "    \n",
        "    You're supposed to \"apply\" above layers to produce new tensors.\n",
        "    Follow inline instructions to complete the function.\n",
        "    \"\"\"\n",
        "    # convert character id into embedding\n",
        "    x_t_emb = embed_x(tf.reshape(x_t, [-1, 1]))[:, 0]\n",
        "    \n",
        "    # concatenate x_t embedding and previous h_t state\n",
        "    x_and_h = tf.concat([x_t_emb, h_t], 1) ### YOUR CODE HERE\n",
        "    \n",
        "    # compute next state given x_and_h\n",
        "    h_next = get_h_next(x_and_h)### YOUR CODE HERE\n",
        "    \n",
        "    # get probabilities for language model P(x_next|h_next)\n",
        "    output_probas = get_probas(h_next) ### YOUR CODE HERE\n",
        "    \n",
        "    return output_probas, h_next"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t-0Tk7r9UHSd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# RNN: loop\n",
        "\n",
        "Once `rnn_one_step` is ready, let's apply it in a loop over name characters to get predictions.\n",
        "\n",
        "Let's assume that all names are at most length-16 for now, so we can simply iterate over them in a for loop.\n"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.342948Z",
          "start_time": "2018-08-13T20:26:44.056136Z"
        },
        "id": "GZDPIvo9UHSd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, MAX_LENGTH))  # batch of token ids\n",
        "batch_size = tf.shape(input_sequence)[0]\n",
        "\n",
        "predicted_probas = []\n",
        "h_prev = tf.zeros([batch_size, rnn_num_units])  # initial hidden state\n",
        "\n",
        "for t in range(MAX_LENGTH):\n",
        "    x_t = input_sequence[:, t]  # column t\n",
        "    probas_next, h_next = rnn_one_step(x_t, h_prev)\n",
        "    \n",
        "    h_prev = h_next\n",
        "    predicted_probas.append(probas_next)\n",
        "    \n",
        "# combine predicted_probas into [batch, time, n_tokens] tensor\n",
        "predicted_probas = tf.transpose(tf.stack(predicted_probas), [1, 0, 2])\n",
        "\n",
        "# next to last token prediction is not needed\n",
        "predicted_probas = predicted_probas[:, :-1, :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r6SLUKkkUHSg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# RNN: loss and gradients\n",
        "\n",
        "Let's gather a matrix of predictions for $P(x_{next}|h)$ and the corresponding correct answers.\n",
        "\n",
        "We will flatten our matrices to shape [None, n_tokens] to make it easier.\n",
        "\n",
        "Our network can then be trained by minimizing crossentropy between predicted probabilities and those answers."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.354310Z",
          "start_time": "2018-08-13T20:26:44.344648Z"
        },
        "id": "BxAsG85EUHSh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# flatten predictions to [batch*time, n_tokens]\n",
        "predictions_matrix = tf.reshape(predicted_probas, [-1, n_tokens])\n",
        "\n",
        "# flatten answers (next tokens) and one-hot encode them\n",
        "answers_matrix = tf.one_hot(tf.reshape(input_sequence[:, 1:], [-1]), n_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZRDIZsBXUHSk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Usually it's a good idea to ignore gradients of loss for padding token predictions.\n",
        "\n",
        "Because we don't care about further prediction after the pad_token is predicted for the first time, so it doesn't make sense to punish our network after the pad_token is predicted.\n",
        "\n",
        "For simplicity you can ignore this comment, it's up to you."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:45.076642Z",
          "start_time": "2018-08-13T20:26:44.355594Z"
        },
        "id": "DF00nMSgUHSl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "1cbf63b9-b3d1-4d0d-d064-795aca83104f"
      },
      "cell_type": "code",
      "source": [
        "# Define the loss as categorical cross-entropy (e.g. from keras.losses).\n",
        "# Mind that predictions are probabilities and NOT logits!\n",
        "# Remember to apply tf.reduce_mean to get a scalar loss!\n",
        "from keras.objectives import categorical_crossentropy\n",
        "loss = tf.reduce_mean(categorical_crossentropy(answers_matrix, predictions_matrix))\n",
        "\n",
        "optimize = tf.train.AdamOptimizer().minimize(loss)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2745: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OorxbnXGUHSp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# RNN: training"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.322187Z",
          "start_time": "2018-08-13T20:26:45.078296Z"
        },
        "id": "6XfmNEseUHSr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "7d7d6857-a006-4b1a-86b3-0221cdd2440d"
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "from random import sample\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "batch_size = 32\n",
        "history = []\n",
        "\n",
        "for i in range(1000):\n",
        "    batch = to_matrix(sample(names, batch_size), max_len=MAX_LENGTH)\n",
        "    loss_i, _ = s.run([loss, optimize], {input_sequence: batch})\n",
        "    \n",
        "    history.append(loss_i)\n",
        "    \n",
        "    if (i + 1) % 100 == 0:\n",
        "        clear_output(True)\n",
        "        plt.plot(history, label='loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge\""
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD4CAYAAADxeG0DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njpuBgwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fbde21455c0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "IAQm7bHDUHSv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# RNN: sampling\n",
        "Once we've trained our network a bit, let's get to actually generating stuff. All we need is the `rnn_one_step` function you have written above."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.341196Z",
          "start_time": "2018-08-13T20:26:55.323787Z"
        },
        "id": "f3iAXYa9UHSx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_t = tf.placeholder(tf.int32, (1,))\n",
        "h_t = tf.Variable(np.zeros([1, rnn_num_units], np.float32))  # we will update hidden state in this variable\n",
        "\n",
        "# For sampling we need to define `rnn_one_step` tensors only once in our graph.\n",
        "# We reuse all parameters thanks to functional API usage.\n",
        "# Then we can feed appropriate tensor values using feed_dict in a loop.\n",
        "# Note how different it is from training stage, where we had to unroll the whole sequence for backprop.\n",
        "next_probs, next_h = rnn_one_step(x_t, h_t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.346422Z",
          "start_time": "2018-08-13T20:26:55.342659Z"
        },
        "id": "IIXOPk-gUHS0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generate_sample(seed_phrase=start_token, max_length=MAX_LENGTH):\n",
        "    '''\n",
        "    This function generates text given a `seed_phrase` as a seed.\n",
        "    Remember to include start_token in seed phrase!\n",
        "    Parameter `max_length` is used to set the number of characters in prediction.\n",
        "    '''\n",
        "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
        "    s.run(tf.assign(h_t, h_t.initial_value))\n",
        "    \n",
        "    # feed the seed phrase, if any\n",
        "    for ix in x_sequence[:-1]:\n",
        "         s.run(tf.assign(h_t, next_h), {x_t: [ix]})\n",
        "    \n",
        "    # start generating\n",
        "    for _ in range(max_length-len(seed_phrase)):\n",
        "        x_probs,_ = s.run([next_probs, tf.assign(h_t, next_h)], {x_t: [x_sequence[-1]]})\n",
        "        x_sequence.append(np.random.choice(n_tokens, p=x_probs[0]))\n",
        "        \n",
        "    return ''.join([tokens[ix] for ix in x_sequence if tokens[ix] != pad_token])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:58.458115Z",
          "start_time": "2018-08-13T20:26:55.347900Z"
        },
        "id": "2QHVHDYXUHS3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "34dcb5ce-9528-49dd-bd71-253a313b872b"
      },
      "cell_type": "code",
      "source": [
        "# without prefix\n",
        "for _ in range(10):\n",
        "    print(generate_sample())"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Lasdenan\n",
            " Pehnellal\n",
            " Malparnos\n",
            " Lighy\n",
            " Darssa\n",
            " Piena\n",
            " Beseetbe\n",
            " Feegne\n",
            " Macthanetta\n",
            " Merl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:01.986726Z",
          "start_time": "2018-08-13T20:26:58.459810Z"
        },
        "id": "Ta8ehGi2UHS5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "32e686ac-9e5d-4843-e4fd-2725cc2590d2"
      },
      "cell_type": "code",
      "source": [
        "# with prefix conditioning\n",
        "for _ in range(10):\n",
        "    print(generate_sample(' Trump'))"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Trumpennna\n",
            " Trumpritta\n",
            " Trumphans\n",
            " Trumponta\n",
            " Trumpeye\n",
            " Trumpellalt\n",
            " Trumpo\n",
            " Trumpef\n",
            " Trumphy\n",
            " Trumpie\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Gf_7koqFUHS8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Submit to Coursera"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:02.004926Z",
          "start_time": "2018-08-13T20:40:02.000821Z"
        },
        "id": "o9BcE4hMUHS9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# token expires every 30 min\n",
        "COURSERA_TOKEN = \"uw67yrcEUcFAOjMT\"\n",
        "COURSERA_EMAIL = \"csit.saurabh@gmail.com\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:18.923357Z",
          "start_time": "2018-08-13T20:40:03.549343Z"
        },
        "id": "RchsqGoVUHS_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "ae419864-a12c-4762-91c5-04fe6e6d966a"
      },
      "cell_type": "code",
      "source": [
        "from submit import submit_char_rnn\n",
        "samples = [generate_sample(' Al') for i in tqdm_utils.tqdm_notebook_failsafe(range(25))]\n",
        "submission = (history, samples)\n",
        "submit_char_rnn(submission, COURSERA_EMAIL, COURSERA_TOKEN)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*************************\n",
            "\n",
            "Submitted to Coursera platform. See results on assignment page!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cO6b2YMcUHTC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Try it out!\n",
        "\n",
        "__Disclaimer:__ This part of assignment is entirely optional. You won't receive bonus points for it. However, it's a fun thing to do. Please share your results on course forums.\n",
        "\n",
        "You've just implemented a recurrent language model that can be tasked with generating any kind of sequence, so there's plenty of data you can try it on:\n",
        "\n",
        "* Novels/poems/songs of your favorite author\n",
        "* News titles/clickbait titles\n",
        "* Source code of Linux or Tensorflow\n",
        "* Molecules in [smiles](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) format\n",
        "* Melody in notes/chords format\n",
        "* IKEA catalog titles\n",
        "* Pokemon names\n",
        "* Cards from Magic, the Gathering / Hearthstone\n",
        "\n",
        "If you're willing to give it a try, here's what you wanna look at:\n",
        "* Current data format is a sequence of lines, so a novel can be formatted as a list of sentences. Alternatively, you can change data preprocessing altogether.\n",
        "* While some datasets are readily available, others can only be scraped from the web. Try `Selenium` or `Scrapy` for that.\n",
        "* Make sure MAX_LENGTH is adjusted for longer datasets. There's also a bonus section about dynamic RNNs at the bottom.\n",
        "* More complex tasks require larger RNN architecture, try more neurons or several layers. It would also require more training iterations.\n",
        "* Long-term dependencies in music, novels or molecules are better handled with LSTM or GRU\n",
        "\n",
        "__Good hunting!__"
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "W9-PGmVHUHTD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Bonus level: dynamic RNNs\n",
        "\n",
        "Apart from Keras, there's also a friendly TensorFlow API for recurrent neural nets. It's based around the symbolic loop function (aka [tf.scan](https://www.tensorflow.org/api_docs/python/tf/scan)).\n",
        "\n",
        "RNN loop that we implemented for training can be replaced with single TensorFlow instruction: [tf.nn.dynamic_rnn](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn).\n",
        "This interface allows for dynamic sequence length and comes with some pre-implemented architectures.\n",
        "\n",
        "Take a look at [tf.nn.rnn_cell.BasicRNNCell](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicRNNCell)."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.975354Z",
          "start_time": "2018-08-13T20:27:12.737529Z"
        },
        "id": "hcgbu9xbUHTE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "f457c50e-fd04-4b74-da14-e9adbc7fe1a0"
      },
      "cell_type": "code",
      "source": [
        "class CustomRNN(tf.nn.rnn_cell.BasicRNNCell):\n",
        "    def call(self, input, state):\n",
        "        # from docs:\n",
        "        # Returns:\n",
        "        # Output: A 2-D tensor with shape [batch_size, self.output_size].\n",
        "        # New state: Either a single 2-D tensor, or a tuple of tensors matching the arity and shapes of state.\n",
        "        return rnn_one_step(input[:, 0], state)\n",
        "    \n",
        "    @property\n",
        "    def output_size(self):\n",
        "        return n_tokens\n",
        "    \n",
        "cell = CustomRNN(rnn_num_units)\n",
        "\n",
        "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
        "    \n",
        "predicted_probas, last_state = tf.nn.dynamic_rnn(cell, input_sequence[:, :, None], dtype=tf.float32)\n",
        "\n",
        "print('LSTM outputs for each step [batch,time,n_tokens]:')\n",
        "print(predicted_probas.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-97-5f3812e903bf>:13: BasicRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.SimpleRNNCell, and will be replaced by that in Tensorflow 2.0.\n",
            "LSTM outputs for each step [batch,time,n_tokens]:\n",
            "(10, 50, 56)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DWjM8ZWHUHTH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Note that we never used MAX_LENGTH in the code above: TF will iterate over however many time-steps you gave it.\n",
        "\n",
        "You can also use any pre-implemented RNN cell:"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.981697Z",
          "start_time": "2018-08-13T20:27:12.977590Z"
        },
        "id": "KLQForYFUHTH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "96336fa2-a9d9-40ae-db25-838affc1e616"
      },
      "cell_type": "code",
      "source": [
        "for obj in dir(tf.nn.rnn_cell) + dir(tf.contrib.rnn):\n",
        "    if obj.endswith('Cell'):\n",
        "        print(obj, end=\"\\t\")"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BasicLSTMCell\tBasicRNNCell\tGRUCell\tLSTMCell\tMultiRNNCell\tRNNCell\tBasicLSTMCell\tBasicRNNCell\tBidirectionalGridLSTMCell\tConv1DLSTMCell\tConv2DLSTMCell\tConv3DLSTMCell\tConvLSTMCell\tCoupledInputForgetGateLSTMCell\tFusedRNNCell\tGLSTMCell\tGRUBlockCell\tGRUCell\tGridLSTMCell\tIndRNNCell\tIndyGRUCell\tIndyLSTMCell\tIntersectionRNNCell\tLSTMBlockCell\tLSTMBlockFusedCell\tLSTMCell\tLayerNormBasicLSTMCell\tLayerRNNCell\tMultiRNNCell\tNASCell\tPhasedLSTMCell\tRNNCell\tSRUCell\tTimeFreqLSTMCell\tUGRNNCell\t"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:13.168207Z",
          "start_time": "2018-08-13T20:27:12.986884Z"
        },
        "id": "psotGOPiUHTL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "8954816d-be70-4bc9-a342-10779524c580"
      },
      "cell_type": "code",
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
        "\n",
        "inputs_embedded = embed_x(input_sequence)\n",
        "\n",
        "# standard cell returns hidden state as output!\n",
        "cell = tf.nn.rnn_cell.LSTMCell(rnn_num_units)\n",
        "\n",
        "state_sequence, last_state = tf.nn.dynamic_rnn(cell, inputs_embedded, dtype=tf.float32)\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "print('LSTM hidden state for each step [batch,time,rnn_num_units]:')\n",
        "print(state_sequence.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LSTM hidden state for each step [batch,time,rnn_num_units]:\n",
            "(10, 50, 64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0I-I3MZoDpVl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}