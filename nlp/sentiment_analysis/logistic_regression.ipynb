{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from argparse import Namespace\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace(\n",
    "    train_file_path = './data/raw_data/labeledTrainData.tsv',\n",
    "    test_file_path = './data/raw_data/testData.tsv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Data\n",
    "train_df = pd.read_csv(args.train_file_path, delimiter='\\t')\n",
    "test_df = pd.read_csv(args.test_file_path, delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split data into train and val data\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_df['review'].tolist(),train_df['sentiment'].tolist(), test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17500, 17500, 7500, 7500)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(y_train), len(X_val), len(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TreebankWordTokenizer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = stopwords.words('english')\n",
    "remove_words = string.punctuation + '0123456789'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_review(review):\n",
    "    \n",
    "    review = BeautifulSoup(review).get_text()    \n",
    "    review = re.sub('^\\w+','', review)\n",
    "    tokens = tokenizer.tokenize(review)\n",
    "    clean_tokens = [lemmatizer.lemmatize(w.lower()) for w in tokens if w not in stop_words and w not in remove_words and w.isalpha()]\n",
    "    \n",
    "    return clean_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_freq(reviews, labels, threshold = 2):\n",
    "    freqs = defaultdict(int)\n",
    "    \n",
    "    for review, label in zip(reviews, labels):\n",
    "        clean_review = process_review(review)\n",
    "        for w in clean_review:\n",
    "            freqs[(w,label)] += 1\n",
    "            \n",
    "    freqs = {w:v for w,v in freqs.items() if v>threshold}\n",
    "                \n",
    "    return freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature(review, freqs):\n",
    "    \n",
    "    # feature : [1, sum_of_pos_word_freq, sum_of_neg_word_freq]\n",
    "    \n",
    "    X = np.zeros(3)\n",
    "    X[0] = 1\n",
    "    \n",
    "    for w in process_review(review):\n",
    "        X[1] += freqs.get((w,1),0)\n",
    "        X[2] += freqs.get((w,0),0)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bild Vocab\n",
    "freqs = build_freq(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train Features\n",
    "X_train_features = list(map(lambda x: create_feature(x, freqs),X_train))\n",
    "X_train_features = np.vstack(X_train_features)\n",
    "y_train_features = np.array(y_train)\n",
    "\n",
    "## Val fetaures\n",
    "X_val_features = list(map(lambda x: create_feature(x, freqs),X_val))\n",
    "X_val_features = np.vstack(X_val_features)\n",
    "y_val_features = np.array(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy : 0.6746285714285715\n",
      "Val Accuracy : 0.6748\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train_features,y_train_features)\n",
    "\n",
    "print(f\"Train Accuracy : {model.score(X_train_features,y_train_features)}\")\n",
    "print(f\"Val Accuracy : {model.score(X_val_features,y_val_features)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Test Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test fetaures\n",
    "X_test_features = list(map(lambda x: create_feature(x, freqs),test_df.review.tolist()))\n",
    "X_test_features = np.vstack(X_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test_features)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
