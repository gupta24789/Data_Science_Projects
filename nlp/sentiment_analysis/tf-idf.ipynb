{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import tqdm\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from argparse import Namespace\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace(\n",
    "    train_file_path = './data/raw_data/labeledTrainData.tsv',\n",
    "    test_file_path = './data/raw_data/testData.tsv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Data\n",
    "train_df = pd.read_csv(args.train_file_path, delimiter='\\t')\n",
    "test_df = pd.read_csv(args.test_file_path, delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split data into train and val data\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_df['review'].tolist(),train_df['sentiment'].tolist(), \n",
    "                                                  test_size = 0.3,\n",
    "                                                 random_state = 121)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17500, 17500, 7500, 7500)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(y_train), len(X_val), len(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TweetTokenizer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = stopwords.words('english')\n",
    "remove_words = string.punctuation + '0123456789'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_review(review):\n",
    "    \n",
    "    review = BeautifulSoup(review).get_text()    \n",
    "    review = re.sub('^\\w+','', review)\n",
    "    review = re.sub('[.]','', review)\n",
    "    tokens = tokenizer.tokenize(review)\n",
    "    tokens = [lemmatizer.lemmatize(w.lower()) for w in tokens]\n",
    "    clean_tokens = [w for w in tokens if w not in stop_words and w not in remove_words]\n",
    "    \n",
    "    return \" \".join(clean_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_X_train = list(map(lambda x: process_review(x),X_train))\n",
    "clean_X_val = list(map(lambda x: process_review(x),X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20788"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create TF-IDF matrix on train data\n",
    "vectorizer = TfidfVectorizer(min_df=5, ngram_range=(1,1))\n",
    "X_train_features = vectorizer.fit_transform(clean_X_train)\n",
    "len(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train_features,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy : 0.9320571428571428\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train Accuracy : {model.score(X_train_features,y_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy : 0.8864\n"
     ]
    }
   ],
   "source": [
    "## Convert into features\n",
    "X_val_features = vectorizer.transform(clean_X_val)\n",
    "print(f\"Val Accuracy : {model.score(X_val_features,y_val)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66323"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create TF-IDF matrix on train data\n",
    "vectorizer = TfidfVectorizer(min_df=5, ngram_range=(1,2))\n",
    "X_train_features = vectorizer.fit_transform(clean_X_train)\n",
    "len(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train_features,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy : 0.9466857142857142\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train Accuracy : {model.score(X_train_features,y_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy : 0.8884\n"
     ]
    }
   ],
   "source": [
    "## Convert into features\n",
    "X_val_features = vectorizer.transform(clean_X_val)\n",
    "print(f\"Val Accuracy : {model.score(X_val_features,y_val)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
