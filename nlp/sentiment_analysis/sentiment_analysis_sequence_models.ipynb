{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os\nimport re\nimport shutil\nimport json\nfrom tqdm import tqdm\nimport string\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import TweetTokenizer, TreebankWordTokenizer\nimport pandas as pd\nimport numpy as np\nimport warnings\nfrom argparse import Namespace\nfrom bs4 import BeautifulSoup\nfrom nltk.stem import WordNetLemmatizer\nfrom collections import defaultdict\nfrom sklearn.model_selection import train_test_split\n\nimport matplotlib.pyplot as plt\nwarnings.filterwarnings('ignore')\n\n\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Set seed \nseed = 121\nnp.random.seed(seed)\ntorch.random.manual_seed(seed)","execution_count":2,"outputs":[{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"<torch._C.Generator at 0x7f3c0ed74c50>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ndevice","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"'cuda'"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"args = Namespace(\n    train_file_path = '../input/bag-of-words-meets-bags-of-popcorn-/labeledTrainData.tsv',\n    test_file_path = '../input/bag-of-words-meets-bags-of-popcorn-/testData.tsv',\n    \n    model_dir = 'models'\n)\n\nif os.path.exists(args.model_dir):\n    shutil.rmtree(args.model_dir)\nos.makedirs(args.model_dir, exist_ok=True)","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Load Data\ntrain_df = pd.read_csv(args.train_file_path, delimiter='\\t')\ntest_df = pd.read_csv(args.test_file_path, delimiter='\\t')","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Split data into train and val data\nX_train, X_val, y_train, y_val = train_test_split(train_df['review'].tolist(),\n                                                  train_df['sentiment'].tolist(), \n                                                  test_size = 0.3,\n                                                  random_state = 121)","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(X_train), len(y_train), len(X_val), len(y_val)","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"(17500, 17500, 7500, 7500)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer = TreebankWordTokenizer()\nlemmatizer = WordNetLemmatizer()\nstop_words = stopwords.words('english')\nremove_words = string.punctuation + '0123456789'","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def process_review(review):\n    \n    review = BeautifulSoup(review).get_text()    \n    review = re.sub('^\\w+','', review)\n    review = re.sub('[.]','', review)\n    tokens = tokenizer.tokenize(review)\n    tokens = [w.lower() for w in tokens]\n    clean_tokens = [w for w in tokens if w not in stop_words and w not in list(remove_words)]\n    \n    \n    return clean_tokens\n\n## Build Vocab\ndef build_vocab(reviews, threshold = 1, special_tokens = None):\n    \n    vocab = defaultdict(int)\n    \n    for review in reviews:\n        for w in review:\n            vocab[w] += 1\n    \n    \n    vocab = [w for w,v in vocab.items() if v>threshold]\n    \n    if special_tokens:\n        vocab = special_tokens + vocab\n    \n    vocab = {w:i for i,w in enumerate(vocab)}\n    \n    return vocab\n\n\ndef convert_review_to_feature(clean_review, vocab, unknown_token = '__UNK__'):\n    \n    feature = []\n    \n    for w in clean_review:\n        if w in vocab:\n            feature.append(vocab[w])\n        else:\n            feature.append(vocab[unknown_token])\n            \n    return feature\n\n\ndef add_padding(feature, max_len, pad_token_idx = 0):\n    \n    \n    if len(feature)>max_len:\n        feature = feature[:max_len]\n\n    diff = max_len - len(feature)\n\n    padding = [pad_token_idx] * diff\n\n    feature += padding\n    \n    return feature","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Clean Data\nclean_X_train = list(map(lambda x: process_review(x), X_train))\nclean_X_val = list(map(lambda x: process_review(x), X_val))","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Build Vocab\nspecial_tokens = ['__UNK__', '__PAD__']\nvocab = build_vocab(clean_X_train, threshold=2,special_tokens = special_tokens)\nlen(vocab)","execution_count":11,"outputs":[{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"36689"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Find max length of review\nlength_dist = pd.Series(list(map(lambda x: len(x), clean_X_train)))\nlength_dist.plot(kind = 'kde')","execution_count":12,"outputs":[{"output_type":"execute_result","execution_count":12,"data":{"text/plain":"<matplotlib.axes._subplots.AxesSubplot at 0x7f3be5de8810>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"length_dist[length_dist <=400].shape[0]/length_dist.shape[0]","execution_count":13,"outputs":[{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"0.9746285714285714"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_len = 400","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_features = list(map(lambda x: convert_review_to_feature(x, vocab),clean_X_train))\nX_val_features = list(map(lambda x: convert_review_to_feature(x, vocab),clean_X_val))\n\nX_train_padded = list(map(lambda x: add_padding(x,max_len= max_len, pad_token_idx=vocab['__PAD__']),X_train_features))\nX_val_padded = list(map(lambda x: add_padding(x,max_len= max_len, pad_token_idx=vocab['__PAD__']),X_val_features))","execution_count":15,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Preparation"},{"metadata":{"trusted":true},"cell_type":"code","source":"class SentimentDataset(Dataset):\n    \n    def __init__(self,reviews,labels):\n        super(SentimentDataset, self)\n        self.reviews = reviews\n        self.labels = labels\n        \n    \n    def __getitem__(self, index):\n        return {'review': self.reviews[index], 'label': self.labels[index]}\n    \n    \n    def __len__(self):\n        return len(self.reviews)\n    \n    \n    \nclass DataLoaderWrapper:\n    \n    def __init__(self, device, dataset, batch_size, shuffle, input_dim = 3):\n        self.device = device\n        self.dataset = dataset\n        self.dataset_size = len(dataset)\n        self.shuffle = shuffle\n        self.batch_size = batch_size\n        self.input_dim = input_dim\n        \n    def __iter__(self):\n        \n        dataloader = DataLoader(self.dataset,batch_size = self.batch_size,shuffle = self.shuffle)\n    \n        for data in dataloader:\n            review = torch.stack(data['review']).T\n            label = data['label']\n            if self.input_dim == 3:\n                review = review.unsqueeze(dim = 2)\n            yield review.to(device), label.to(device)\n            \n    def get_number_of_batches(self):\n        return int(np.round(len(self.dataset)/self.batch_size,0))","execution_count":16,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Modeling"},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_fn(model,dataloader,optimizer, loss_fn, data_type):\n        \n        \n        ## training phase\n        model.train()\n        \n        running_loss = 0\n        correct = 0        \n        number_of_batches = dataloader.get_number_of_batches()\n        dataset_size = dataloader.dataset_size\n        \n       \n        for review, label in dataloader:\n            \n            ## reset optimizer\n            optimizer.zero_grad()\n            \n            if data_type == 'float':\n                probs = model(review.float())\n            elif data_type == 'long':\n                probs = model(review.long())\n            else:\n                pribs = model(review)\n                \n            loss = loss_fn(probs, label)\n            loss.backward()\n            optimizer.step()\n            \n            running_loss += loss.item()\n            pred_labels = torch.argmax(probs, dim = 1)\n            correct += torch.sum(pred_labels == label).item()\n        \n        epoch_running_loss = running_loss/number_of_batches\n        accuracy = correct/dataset_size\n        \n        return epoch_running_loss, accuracy\n\n    \ndef eval_fn(model,dataloader,optimizer, loss_fn, data_type):\n        \n        ## validation phase\n        model.eval()\n        \n        running_loss = 0\n        correct = 0\n        number_of_batches = dataloader.get_number_of_batches()\n        dataset_size = dataloader.dataset_size\n        \n        for review, label in dataloader:\n            if data_type == 'float':\n                probs = model(review.float())\n            elif data_type == 'long':\n                probs = model(review.long())\n            else:\n                pribs = model(review)\n                \n            loss = loss_fn(probs, label)\n            running_loss += loss.item()\n            pred_labels = torch.argmax(probs, dim = 1)\n            \n            running_loss += loss.item()\n            correct += torch.sum(pred_labels == label).item()\n            \n        \n        epoch_running_loss = running_loss/number_of_batches\n        accuracy = correct/dataset_size\n        \n        return epoch_running_loss, accuracy\n    \n    \ndef train(model,train_dataloader,val_dataloader, epochs, optimizer, loss_fn, verbose = True, data_type = 'float'):\n\n    print(\"Training Starts  \")\n    best_val_loss = 100000\n\n    for epoch in range(epochs):\n\n        ## Training\n        train_loss, train_acc = train_fn(model,train_dataloader, optimizer, loss_fn, data_type)\n        \n        ## Validation\n        val_loss, val_acc = eval_fn(model,val_dataloader, optimizer, loss_fn, data_type)\n\n        if verbose: \n            loss_log = f\" Train loss: {train_loss:.3f}  Val loss: {val_loss:.3f}\"\n            acc_log = f\" Train accuracy : {train_acc:.3f}  Val accuarcy : {val_acc:.3f}\"\n            print(f\"Epoch : {epoch} \"+ loss_log + acc_log)\n\n\n        if best_val_loss > val_loss:\n            best_val_loss = val_loss\n            model_path = f\"models/epoch_{epoch}_best_val_loss_model.model\"\n            torch.save(model.state_dict(), model_path)","execution_count":17,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" ## Data For RNNs"},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 5\nbatch_size = 32\nlearning_rate = 0.00001\n\n## Prepare data\ntrain_dataset = SentimentDataset(X_train_padded, y_train)\nval_dataset = SentimentDataset(X_val_padded, y_val)\n\ntrain_dl = DataLoaderWrapper(device, train_dataset, batch_size, True, input_dim=3)\nval_dl = DataLoaderWrapper(device, val_dataset, batch_size, False, input_dim=3)","execution_count":18,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Simple RNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Input data must have dim : [batch_size, seq_len, input_size]\n## RNN returns : out, hidden\n# out : [batch, seq_len, num_directions * hidden_size]\n# hidden : [num_layers * num_directions, batch, hidden_size]\n# num_directions = 2 for bidirectional RNNs and 1 otherwise.\n\n\nclass SimpleRNN(nn.Module):\n    \n    def __init__(self, seq_len,input_size, output_dim):\n        super(SimpleRNN, self).__init__()\n        \n        self.rnn1 = nn.RNN(input_size = input_size, hidden_size = 300, batch_first = True)\n        self.rnn2 = nn.RNN(input_size= 300, hidden_size = 100, batch_first= True)\n        \n        self.dropout=nn.Dropout(0.2)\n        \n        self.flatten  = nn.Flatten()\n        self.linear1 = nn.Linear(in_features= 100 * seq_len, out_features= 256)\n        self.linear2 = nn.Linear(in_features= 256, out_features= output_dim)\n        \n    \n    def forward(self, review):\n        \n        out, hidden = self.rnn1(review)\n        out, hidden = self.rnn2(out)\n        \n        output = self.flatten(out)\n        \n        output = self.linear1(output)\n        output = self.dropout(output)\n        output = self.linear2(output)\n        output = F.softmax(output,dim = 1)\n        return output","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Prapare training\nmodel = SimpleRNN(seq_len= max_len,input_size=1, output_dim=2)\nloss_fn = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr = learning_rate)\n\n## Training\nmodel.to(device)\ntrain(model,train_dl, val_dl,epochs, optimizer, loss_fn, data_type = 'float')","execution_count":20,"outputs":[{"output_type":"stream","text":"Training Starts  \nEpoch : 0  Train loss: 0.700  Val loss: 1.389 Train accuracy : 0.520  Val accuarcy : 0.517\nEpoch : 1  Train loss: 0.687  Val loss: 1.390 Train accuracy : 0.544  Val accuarcy : 0.526\nEpoch : 2  Train loss: 0.681  Val loss: 1.397 Train accuracy : 0.560  Val accuarcy : 0.527\nEpoch : 3  Train loss: 0.676  Val loss: 1.404 Train accuracy : 0.570  Val accuarcy : 0.530\nEpoch : 4  Train loss: 0.671  Val loss: 1.388 Train accuracy : 0.576  Val accuarcy : 0.540\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# LSTM RNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"class LSTMRNN(nn.Module):\n    \n    def __init__(self, seq_len,input_size, output_dim):\n        super(LSTMRNN, self).__init__()\n        \n        self.lstm1 = nn.LSTM(input_size = input_size, hidden_size = 200, batch_first = True)\n        self.lstm2 = nn.LSTM(input_size= 200, hidden_size = 50, batch_first= True)\n        self.dropout=nn.Dropout(0.2)\n        self.flatten  = nn.Flatten()\n        self.linear1 = nn.Linear(in_features= 50 * seq_len, out_features= 256)\n        self.linear2 = nn.Linear(in_features= 256, out_features= output_dim)\n        \n    \n    def forward(self, review):\n        \n        out, (h_n, c_n) = self.lstm1(review)\n        out, (h_n, c_n) = self.lstm2(out)\n        \n        output = self.flatten(out)\n        output = self.linear1(output)\n        output = self.dropout(output)\n        output = self.linear2(output)\n        output = F.softmax(output,dim = 1)\n    \n        return output","execution_count":21,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Prapare training\nmodel = LSTMRNN(seq_len= max_len,input_size=1, output_dim=2)\nloss_fn = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr = learning_rate)\n\n## Training\nmodel.to(device)\ntrain(model,train_dl, val_dl,epochs, optimizer, loss_fn, data_type = 'float')","execution_count":null,"outputs":[{"output_type":"stream","text":"Training Starts  \nEpoch : 0  Train loss: 0.693  Val loss: 1.387 Train accuracy : 0.513  Val accuarcy : 0.535\nEpoch : 1  Train loss: 0.691  Val loss: 1.385 Train accuracy : 0.531  Val accuarcy : 0.528\nEpoch : 2  Train loss: 0.687  Val loss: 1.378 Train accuracy : 0.545  Val accuarcy : 0.542\nEpoch : 3  Train loss: 0.683  Val loss: 1.370 Train accuracy : 0.557  Val accuarcy : 0.557\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# BiLSTM RNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"class BiLSTMRNN(nn.Module):\n    \n    def __init__(self, seq_len,input_size, output_dim):\n        super(BiLSTMRNN, self).__init__()\n        \n        self.bilstm1 = nn.LSTM(input_size = input_size, hidden_size = 100, batch_first = True, bidirectional = True)\n        self.bilstm2 = nn.LSTM(input_size= 200, hidden_size = 50, batch_first= True, bidirectional = True)\n        self.dropout = nn.Dropout(0.2)\n        self.flatten  = nn.Flatten()\n        self.linear1 = nn.Linear(in_features= 100 * seq_len, out_features= 256)\n        self.linear2 = nn.Linear(in_features= 256, out_features= output_dim)\n        \n    \n    def forward(self, review):\n        \n        out, (h_n, c_n) = self.bilstm1(review)\n        out, (h_n, c_n) = self.bilstm2(F.relu(out))\n        \n        output = self.flatten(F.relu(out))\n        output = self.linear1(output)\n        output = self.dropout(output)\n        output = self.linear2(output)\n        output = F.softmax(output,dim = 1)\n    \n        return output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Prapare training\nmodel = BiLSTMRNN(seq_len= max_len,input_size=1, output_dim=2)\nloss_fn = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr = learning_rate)\n\n## Training\nmodel.to(device)\ntrain(model,train_dl, val_dl,epochs, optimizer, loss_fn, data_type = 'float')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# BiLSTM with embedding layer"},{"metadata":{"trusted":true},"cell_type":"code","source":"class BiLSTMEmbedding(nn.Module):\n    \n    def __init__(self, seq_len,vocab_size, output_dim):\n        super(BiLSTMEmbedding, self).__init__()\n        \n        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim = 300)\n        self.bilstm1 = nn.LSTM(input_size = 300, hidden_size = 100, batch_first = True, bidirectional = True)\n        self.bilstm2 = nn.LSTM(input_size= 200, hidden_size = 50, batch_first= True, bidirectional = True)\n        \n        self.flatten  = nn.Flatten()\n        self.linear1 = nn.Linear(in_features= 100 * seq_len, out_features= 256)\n        self.linear2 = nn.Linear(in_features= 256, out_features= output_dim)\n        \n    \n    def forward(self, review):\n        \n        embedding = self.embedding(review)\n        out, (h_n, c_n) = self.bilstm1(embedding)\n        out, (h_n, c_n) = self.bilstm2(F.relu(out))\n        \n        output = self.flatten(F.relu(out))\n        output = self.linear1(output)\n        output = F.softmax(self.linear2(output),dim = 1)\n    \n        return output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dl = DataLoaderWrapper(device, train_dataset, batch_size, True, input_dim = 2)\nval_dl = DataLoaderWrapper(device, val_dataset, batch_size, False, input_dim = 2)\n\n\n## Prapare training\nmodel = BiLSTMEmbedding(seq_len= max_len,vocab_size=len(vocab), output_dim=2)\nloss_fn = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr = learning_rate)\n\n## Training\nmodel.to(device)\ntrain(model,train_dl, val_dl,epochs, optimizer, loss_fn, data_type = 'long')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## BiLSTM with Glove embedding"},{"metadata":{"trusted":true},"cell_type":"code","source":"EMBEDDING_DIM = 50\nGLOVE_FILE_PATH = '../input/glove6b50dtxt/glove.6B.50d.txt'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"glove = {}\nwith open(GLOVE_FILE_PATH) as f:\n    for line in f.readlines():\n        k,v = line.split(' ',1)\n        glove[k] = np.array(v.split(' '))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"matrix_len = len(vocab)\nweights_matrix = np.zeros((matrix_len, 50))\nwords_found = 0\n\nfor i, word in enumerate(vocab):\n    try: \n        weights_matrix[i] = glove[word]\n        words_found += 1\n    except KeyError:\n        weights_matrix[i] = np.random.normal(scale=0.6, size=(EMBEDDING_DIM, ))\n        \nweights_matrix = torch.Tensor(weights_matrix)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_emb_layer(weights_matrix, non_trainable=False):\n    \n    num_embeddings, embedding_dim = weights_matrix.size()\n    emb_layer = nn.Embedding(num_embeddings, embedding_dim)\n    emb_layer.load_state_dict({'weight': weights_matrix})\n    if non_trainable:\n        emb_layer.weight.requires_grad = False\n\n    return emb_layer, num_embeddings, embedding_dim","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class BiLSTMGloveEmbedding(nn.Module):\n    \n    def __init__(self, seq_len,vocab_size, output_dim):\n        super(BiLSTMGloveEmbedding, self).__init__()\n        \n        self.embedding, num_embeddings, embedding_dim = create_emb_layer(weights_matrix, True)\n        self.bilstm1 = nn.LSTM(input_size = embedding_dim, hidden_size = 100, batch_first = True, bidirectional = True)\n        self.bilstm2 = nn.LSTM(input_size= 200, hidden_size = 50, batch_first= True, bidirectional = True)\n        \n        self.flatten  = nn.Flatten()\n        self.linear1 = nn.Linear(in_features= 100 * seq_len, out_features= 256)\n        self.linear2 = nn.Linear(in_features= 256, out_features= output_dim)\n        \n    \n    def forward(self, review):\n        \n        embedding = self.embedding(review)\n        out, (h_n, c_n) = self.bilstm1(embedding)\n        out, (h_n, c_n) = self.bilstm2(F.relu(out))\n        \n        output = self.flatten(F.relu(out))\n        output = self.linear1(output)\n        output = F.softmax(self.linear2(output),dim = 1)\n    \n        return output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dl = DataLoaderWrapper(device, train_dataset, batch_size, True, input_dim = 2)\nval_dl = DataLoaderWrapper(device, val_dataset, batch_size, False, input_dim = 2)\n\n\n## Prapare training\nmodel = BiLSTMGloveEmbedding(seq_len= max_len,vocab_size=len(vocab), output_dim=2)\nloss_fn = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr = learning_rate)\n\n## Training\nmodel.to(device)\ntrain(model,train_dl, val_dl,epochs, optimizer, loss_fn, data_type = 'long')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}