{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from argparse import Namespace\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace(\n",
    "    train_file_path = './data/raw_data/labeledTrainData.tsv',\n",
    "    test_file_path = './data/raw_data/testData.tsv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Data\n",
    "train_df = pd.read_csv(args.train_file_path, delimiter='\\t')\n",
    "test_df = pd.read_csv(args.test_file_path, delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split data into train and val data\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_df['review'].tolist(),train_df['sentiment'].tolist(), \n",
    "                                                  test_size = 0.3,\n",
    "#                                                   stratify = train_df['sentiment'],\n",
    "                                                  random_state = 121)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17500, 17500, 7500, 7500)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(y_train), len(X_val), len(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TreebankWordTokenizer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = stopwords.words('english')\n",
    "remove_words = string.punctuation + '0123456789'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_review(review):\n",
    "    \n",
    "    review = BeautifulSoup(review).get_text()    \n",
    "    review = re.sub('^\\w+','', review)\n",
    "    tokens = tokenizer.tokenize(review)\n",
    "    tokens = [lemmatizer.lemmatize(w.lower()) for w in tokens]\n",
    "    clean_tokens = [w for w in tokens if w not in stop_words and w not in remove_words]\n",
    "    \n",
    "    return clean_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_freq(reviews, labels, threshold = 2):\n",
    "    freqs = defaultdict(int)\n",
    "    \n",
    "    Dpos = 0\n",
    "    Dneg = 0\n",
    "    \n",
    "    for review, label in tqdm.tqdm(zip(reviews, labels),total = len(reviews)):\n",
    "        clean_review = process_review(review)\n",
    "        for w in clean_review:\n",
    "            freqs[(w,label)] += 1\n",
    "            \n",
    "        if label == 0:\n",
    "            Dneg += 1\n",
    "        if label == 1:\n",
    "            Dpos += 1\n",
    "            \n",
    "    freqs = {w:v for w,v in freqs.items() if v>threshold}\n",
    "                \n",
    "    return freqs, Dpos, Dneg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17500/17500 [00:58<00:00, 301.63it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(51004, 8702, 8798)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Build Vocab\n",
    "freqs, Dpos, Dneg = build_freq(X_train, y_train)\n",
    "len(freqs), Dpos, Dneg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51004/51004 [03:47<00:00, 224.06it/s]\n"
     ]
    }
   ],
   "source": [
    "## Calculate Probability\n",
    "probs_df = pd.DataFrame()\n",
    "for k,v in tqdm.tqdm(freqs.items()):\n",
    "    probs_df.loc[k[0],k[1]] = v\n",
    "probs_df.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_df.rename(columns = {1:'pos_freq',0:'neg_freq'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalize probability using laplacian smoothing\n",
    "total_pos_freq = probs_df['pos_freq'].sum()\n",
    "total_neg_freq = probs_df['neg_freq'].sum()\n",
    "vocab_size = probs_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_df['pos_prob'] = probs_df['pos_freq'].apply(lambda x: (x+1)/(vocab_size+total_pos_freq))\n",
    "probs_df['neg_prob'] = probs_df['neg_freq'].apply(lambda x: (x+1)/(vocab_size+total_neg_freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_df['lambda'] = probs_df.pos_freq/probs_df.neg_prob\n",
    "probs_df['log_lambda'] = np.log(probs_df['lambda'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_prior = np.log(Dpos/Dneg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_df['log_lambda'] = probs_df['log_lambda'].replace(float('-inf'),-100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_prediction(reviews, log_prior, probs):\n",
    "    \n",
    "    preds = []\n",
    "    reviewVal = 0\n",
    "    for review in tqdm.tqdm(reviews):\n",
    "        reviewVal = 0\n",
    "        for w in process_review(review):\n",
    "            if w in probs.index:\n",
    "                reviewVal += probs.loc[w,'log_lambda']\n",
    "        reviewVal += log_prior\n",
    "        \n",
    "        if reviewVal>0:\n",
    "            preds.append(1)\n",
    "        else:\n",
    "            preds.append(0)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(pred, y_train):\n",
    "    \n",
    "    correct = sum(np.array(pred) == np.array(y_train))\n",
    "    return correct/len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17500/17500 [01:18<00:00, 223.29it/s]\n"
     ]
    }
   ],
   "source": [
    "train_preds = calculate_prediction(X_train, log_prior, probs_df)\n",
    "train_accuracy = calculate_accuracy(train_preds,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7500/7500 [00:33<00:00, 223.45it/s]\n"
     ]
    }
   ],
   "source": [
    "val_preds = calculate_prediction(X_val, log_prior, probs_df)\n",
    "val_accuracy = calculate_accuracy(val_preds,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy : 0.7246857142857143\n",
      "Val accuracy : 0.5958666666666667\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train accuracy : {train_accuracy}\")\n",
    "print(f\"Val accuracy : {val_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
